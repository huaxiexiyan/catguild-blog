<!doctype html><html lang=zh-cn dir=ltr><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="爬虫框架 scrapy 1、创建新项目 scrapy startproject tutorial 2、创建爬虫文件 # 创建普通模版 scrapy genspider 爬虫名字 爬取的域名（不用协议头） # 创建 crawl spider 模版 scrapy genspider -t crawl 爬虫名字 爬取的域名（不用协议头） 3、启动爬虫 scrapy crawl 爬虫名字 项目文件结构 项目名字 项目名字 spiders文件夹（存储的是爬虫文件"><title>爬虫</title><link rel=canonical href=https://www.catguild.cn/category/practical/python/%E7%88%AC%E8%99%AB/><link rel=stylesheet href=/scss/style.min.abbd69b2908fdfcd5179898beaafd374514a86538d81639ddd2c58c06ae54e40.css><meta property="og:title" content="爬虫"><meta property="og:description" content="爬虫框架 scrapy 1、创建新项目 scrapy startproject tutorial 2、创建爬虫文件 # 创建普通模版 scrapy genspider 爬虫名字 爬取的域名（不用协议头） # 创建 crawl spider 模版 scrapy genspider -t crawl 爬虫名字 爬取的域名（不用协议头） 3、启动爬虫 scrapy crawl 爬虫名字 项目文件结构 项目名字 项目名字 spiders文件夹（存储的是爬虫文件"><meta property="og:url" content="https://www.catguild.cn/category/practical/python/%E7%88%AC%E8%99%AB/"><meta property="og:site_name" content="雪乃の猫"><meta property="og:type" content="article"><meta property="article:section" content="Category"><meta name=twitter:title content="爬虫"><meta name=twitter:description content="爬虫框架 scrapy 1、创建新项目 scrapy startproject tutorial 2、创建爬虫文件 # 创建普通模版 scrapy genspider 爬虫名字 爬取的域名（不用协议头） # 创建 crawl spider 模版 scrapy genspider -t crawl 爬虫名字 爬取的域名（不用协议头） 3、启动爬虫 scrapy crawl 爬虫名字 项目文件结构 项目名字 项目名字 spiders文件夹（存储的是爬虫文件"><script async src="https://www.googletagmanager.com/gtag/js?id=G-49K5GYEZX0"></script>
<script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-49K5GYEZX0")</script><script>var _hmt=_hmt||[];(function(){var e,t=document.createElement("script");t.src="https://hm.baidu.com/hm.js?6e15f273a2871fda1150e7f434efa838",e=document.getElementsByTagName("script")[0],e.parentNode.insertBefore(t,e)})()</script></head><body class=article-page><script>(function(){const e="StackColorScheme";localStorage.getItem(e)||localStorage.setItem(e,"auto")})()</script><script>(function(){const t="StackColorScheme",e=localStorage.getItem(t),n=window.matchMedia("(prefers-color-scheme: dark)").matches===!0;e=="dark"||e==="auto"&&n?document.documentElement.dataset.scheme="dark":document.documentElement.dataset.scheme="light"})()</script><div class="container main-container flex on-phone--column compact"><aside class="sidebar left-sidebar sticky"><button class="hamburger hamburger--spin" type=button id=toggle-menu aria-label="Toggle Menu">
<span class=hamburger-box><span class=hamburger-inner></span></span></button><header><figure class=site-avatar><a href=/><img src=/img/avatar_huda2458f72ce188392d75c5d51cd8e24e_373_300x0_resize_box_3.png width=300 height=300 class=site-logo loading=lazy alt=Avatar></a></figure><div class=site-meta><h1 class=site-name><a href=/>雪乃の猫</a></h1><h2 class=site-description></h2></div></header><ol class=menu id=main-menu><li><a href=/archives/><span>⏱时间轴</span></a></li><li><a href=/categories/><span>分类</span></a></li><li><a href=/tags/><span>🔖标签</span></a></li><li><a href=/search/><span>🔍搜索</span></a></li><li><a href=/links/><span>🤝友链</span></a></li><div class=menu-bottom-section><li id=dark-mode-toggle><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-toggle-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="8" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-toggle-right" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="16" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg><span>Dark Mode</span></li></div></ol></aside><main class="main full-width"><article class=main-article><header class=article-header><div class=article-details><div class=article-title-wrapper><h2 class=article-title><a href=/category/practical/python/%E7%88%AC%E8%99%AB/>爬虫</a></h2></div><footer class=article-time><div><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><polyline points="12 7 12 12 15 15"/></svg><time class=article-time--reading>2 minute read</time></div></footer></div></header><section class=article-content><h1 id=爬虫框架-scrapy>爬虫框架 scrapy</h1><p>1、创建新项目</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl>scrapy startproject tutorial
</span></span></code></pre></div><p>2、创建爬虫文件</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl><span class=c1># 创建普通模版</span>
</span></span><span class=line><span class=cl>scrapy genspider 爬虫名字 爬取的域名（不用协议头）
</span></span><span class=line><span class=cl><span class=c1># 创建 crawl spider 模版</span>
</span></span><span class=line><span class=cl>scrapy genspider -t crawl 爬虫名字 爬取的域名（不用协议头）
</span></span></code></pre></div><p>3、启动爬虫</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl>scrapy crawl 爬虫名字
</span></span></code></pre></div><h2 id=项目文件结构>项目文件结构</h2><div class=highlight><pre tabindex=0 class=chroma><code class=language-txt data-lang=txt><span class=line><span class=cl>项目名字
</span></span><span class=line><span class=cl>	项目名字
</span></span><span class=line><span class=cl>		spiders文件夹（存储的是爬虫文件）
</span></span><span class=line><span class=cl>			init
</span></span><span class=line><span class=cl>			自定义的爬虫文件		核心功能文件
</span></span><span class=line><span class=cl>		init
</span></span><span class=line><span class=cl>		items		定义数据结构的地方		爬取的数据包含那些
</span></span><span class=line><span class=cl>		middleware		中间件		代理
</span></span><span class=line><span class=cl>		settings		配置文件		robots协议		ua定义等
</span></span></code></pre></div><h2 id=response的属性和方法>response的属性和方法</h2><div class=highlight><pre tabindex=0 class=chroma><code class=language-txt data-lang=txt><span class=line><span class=cl>response.text	获取的是响应的字符串
</span></span><span class=line><span class=cl>response.body	获取的是二进制数据
</span></span><span class=line><span class=cl>response.xpath	可以直接是xpath方法来解析response中的内容
</span></span><span class=line><span class=cl>response.extract()	提取seletor对象的data属性值
</span></span><span class=line><span class=cl>response.extract_first()	提取seletor列表的第一个数据
</span></span></code></pre></div><h2 id=setting>setting</h2><div class=highlight><pre tabindex=0 class=chroma><code class=language-txt data-lang=txt><span class=line><span class=cl># 需要使用管道，需要打开该设置
</span></span><span class=line><span class=cl>ITEM_PIPELINES = {
</span></span><span class=line><span class=cl>	# 管道可以有多个，并有有优先级，值从1-1000，值越小越高
</span></span><span class=line><span class=cl>	&#39;项目名.pipelines.管道名&#39;: 300
</span></span><span class=line><span class=cl>}
</span></span></code></pre></div><h2 id=下载图片>下载图片</h2><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>urllib.request</span>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>DownLoadPipeline</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>process_item</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>item</span><span class=p>,</span> <span class=n>spider</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>url</span> <span class=o>=</span> <span class=n>item</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s1>&#39;url&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>filename</span><span class=o>=</span><span class=s1>&#39;http://&#39;</span><span class=o>+</span> <span class=n>item</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s1>&#39;name&#39;</span><span class=p>)</span><span class=o>+</span><span class=s1>&#39;.jpg&#39;</span>
</span></span><span class=line><span class=cl>        <span class=n>urllib</span><span class=o>.</span><span class=n>request</span><span class=o>.</span><span class=n>urlretrieve</span><span class=p>(</span><span class=n>url</span> <span class=o>=</span> <span class=n>url</span><span class=p>,</span> <span class=n>filename</span> <span class=o>=</span> <span class=n>filename</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>item</span>
</span></span></code></pre></div><h2 id=部署>部署</h2><p>scrapy部署服务器有一套完整的开源项目：<strong>scrapy+scrapyd(服务端)+scrapy-client(客户端)+scrapydweb</strong>
1、scrapyd(服务端)</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-txt data-lang=txt><span class=line><span class=cl># 官方文档
</span></span><span class=line><span class=cl>https://scrapyd.readthedocs.io
</span></span><span class=line><span class=cl># 安装
</span></span><span class=line><span class=cl>pipenv install scrapyd
</span></span><span class=line><span class=cl># 启动
</span></span><span class=line><span class=cl>scrapyd
</span></span><span class=line><span class=cl># 浏览器访问
</span></span><span class=line><span class=cl>http://127.0.0.1:6800
</span></span></code></pre></div><p>2、scrapy-client
scrapy-client它允许我们将本地的scrapy项目打包发送到scrapyd 这个服务端（前提是服务器scrapyd正常运行）</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-txt data-lang=txt><span class=line><span class=cl># 官方文档
</span></span><span class=line><span class=cl>https://pypi.org/project/scrapyd-client/
</span></span><span class=line><span class=cl># 安装
</span></span><span class=line><span class=cl>pipenv install scrapyd-client
</span></span></code></pre></div><p>3、scrapydweb（可选）</p><p>ScrapydWeb：用于Scrapyd集群管理的Web应用程序，支持Scrapy日志分析和可视化。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-txt data-lang=txt><span class=line><span class=cl>#官方文档
</span></span><span class=line><span class=cl>https://github.com/my8100/scrapydweb/blob/master/README_CN.md
</span></span><span class=line><span class=cl># 安装
</span></span><span class=line><span class=cl>pipenv install scrapydweb
</span></span><span class=line><span class=cl># 运行命令
</span></span><span class=line><span class=cl>scrapydweb
</span></span></code></pre></div><p>运行命令scrapydweb，首次启动将会在当前目录下生成配置文件“scrapydweb_settings_v*.py”</p><p>1、更改配置文件 编辑配置文件，将ENABLE_LOGPARSER更改为False</p><p>2、添加访问权限</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-txt data-lang=txt><span class=line><span class=cl>SCRAPYD_SERVERS = [
</span></span><span class=line><span class=cl>    &#39;127.0.0.1:6800&#39;,
</span></span><span class=line><span class=cl>    # &#39;username:password@localhost:6801#group&#39;,
</span></span><span class=line><span class=cl>    (&#39;username&#39;, &#39;password&#39;, &#39;localhost&#39;, &#39;6801&#39;, &#39;group&#39;),
</span></span><span class=line><span class=cl>]
</span></span></code></pre></div><p>3、添加http认证</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-txt data-lang=txt><span class=line><span class=cl>ENABLE_AUTH = True
</span></span><span class=line><span class=cl>USERNAME = &#39;username&#39;
</span></span><span class=line><span class=cl>PASSWORD = &#39;password&#39;
</span></span></code></pre></div><h2 id=如果启动失败一般是使用了高版本的python>如果启动失败（一般是使用了高版本的python）</h2><div class=highlight><pre tabindex=0 class=chroma><code class=language-txt data-lang=txt><span class=line><span class=cl># 400 错误
</span></span><span class=line><span class=cl>APScheduler==3.9.1
</span></span><span class=line><span class=cl># 500 错误
</span></span><span class=line><span class=cl>SQLAlchemy&gt;=1.2.15,&lt;1.4.0
</span></span></code></pre></div></section><footer class=article-footer></footer></article><footer class=site-footer><section class=copyright>&copy;
2020 -
2023 雪乃の猫</section><section class=powerby><div style=margin:0><a href=https://beian.miit.gov.cn/ target=_blank style=color:#939393>皖ICP备 20012821 号</a>&nbsp;<span><a target=_blank href="http://www.beian.gov.cn/portal/registerSystemInfo?recordcode=34082602201751" style=display:inline-block;text-decoration:none;height:20px;color:#939393><img src=/img/beian.png style="float:left;margin:0 5px 0 0">皖公网安备 34082602201751 号</a></span></div><div class="footer-line thanks"><span class="icp footer-divider">特别感谢
<a href=https://gohugo.io target=_blank rel="external nofollow noopener noreferrer" title="Hugo 0.111.3">Hugo</a> |
<a href=https://github.com/CaiJimmy/hugo-theme-stack target=_blank rel="noopener noreffer" title="Stack 3.20.0">Stack</a> |
<a href=https://github.com target=_blank rel="noopener noreffer">GitHub</a> |
<a href=https://vercel.com target=_blank rel="noopener noreffer">Vercel</a></span></div></section></footer><div class=pswp tabindex=-1 role=dialog aria-hidden=true><div class=pswp__bg></div><div class=pswp__scroll-wrap><div class=pswp__container><div class=pswp__item></div><div class=pswp__item></div><div class=pswp__item></div></div><div class="pswp__ui pswp__ui--hidden"><div class=pswp__top-bar><div class=pswp__counter></div><button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
<button class="pswp__button pswp__button--share" title=Share></button>
<button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
<button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button><div class=pswp__preloader><div class=pswp__preloader__icn><div class=pswp__preloader__cut><div class=pswp__preloader__donut></div></div></div></div></div><div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap"><div class=pswp__share-tooltip></div></div><button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)"></button>
<button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button><div class=pswp__caption><div class=pswp__caption__center></div></div></div></div></div><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js integrity="sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo=" crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU=" crossorigin=anonymous defer></script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css crossorigin=anonymous><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css crossorigin=anonymous></main></div><script src=https://cdn.jsdelivr.net/npm/node-vibrant@3.1.6/dist/vibrant.min.js integrity="sha256-awcR2jno4kI5X0zL8ex0vi2z+KMkF24hUW8WePSA9HM=" crossorigin=anonymous></script><script type=text/javascript src=/ts/main.js defer></script>
<script>(function(){const e=document.createElement("link");e.href="https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&display=swap",e.type="text/css",e.rel="stylesheet",document.head.appendChild(e)})()</script></body></html>