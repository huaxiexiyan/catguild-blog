<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>爬虫 | 猫公会</title><meta name=keywords content><meta name=description content="爬虫框架 scrapy 1、创建新项目 scrapy startproject tutorial 2、创建爬虫文件 # 创建普通模版 scrapy genspider 爬虫名字 爬取的域名（不用协议头） # 创建 crawl spider 模版 scrapy genspider -t crawl 爬虫名字 爬取的域名（不用协议头） 3、启动爬虫 scrapy crawl 爬虫名字 项目文件结构 项目名字 项目名字 spiders文件夹（存储的是爬虫文件"><meta name=author content="
作者:&nbsp;Me"><link rel=canonical href=https://www.catguild.cn/category/practical/python/%E7%88%AC%E8%99%AB/><meta name=yandex-verification content="XYZabc"><meta name=msvalidate.01 content="XYZabc"><link crossorigin=anonymous href=/assets/css/stylesheet.9c7c35e2f76542323b21747a40f1590c09c8cb45d08e4d7c82e632663381bae6.css integrity="sha256-nHw14vdlQjI7IXR6QPFZDAnIy0XQjk18guYyZjOBuuY=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG+9vmJ0cTS+ovo0FeA=" onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=https://www.catguild.cn/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=16x16 href=https://www.catguild.cn/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=32x32 href=https://www.catguild.cn/%3Clink%20/%20abs%20url%3E><link rel=apple-touch-icon href=https://www.catguild.cn/%3Clink%20/%20abs%20url%3E><link rel=mask-icon href=https://www.catguild.cn/%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script async src="https://www.googletagmanager.com/gtag/js?id=G-49K5GYEZX0"></script>
<script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-49K5GYEZX0")</script><script>var _hmt=_hmt||[];(function(){var e,t=document.createElement("script");t.src="https://hm.baidu.com/hm.js?6e15f273a2871fda1150e7f434efa838",e=document.getElementsByTagName("script")[0],e.parentNode.insertBefore(t,e)})()</script><meta property="og:title" content="爬虫"><meta property="og:description" content="爬虫框架 scrapy 1、创建新项目 scrapy startproject tutorial 2、创建爬虫文件 # 创建普通模版 scrapy genspider 爬虫名字 爬取的域名（不用协议头） # 创建 crawl spider 模版 scrapy genspider -t crawl 爬虫名字 爬取的域名（不用协议头） 3、启动爬虫 scrapy crawl 爬虫名字 项目文件结构 项目名字 项目名字 spiders文件夹（存储的是爬虫文件"><meta property="og:type" content="article"><meta property="og:url" content="https://www.catguild.cn/category/practical/python/%E7%88%AC%E8%99%AB/"><meta property="og:image" content="https://www.catguild.cn/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta property="article:section" content="category"><meta property="og:site_name" content="ExampleSite"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://www.catguild.cn/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="爬虫"><meta name=twitter:description content="爬虫框架 scrapy 1、创建新项目 scrapy startproject tutorial 2、创建爬虫文件 # 创建普通模版 scrapy genspider 爬虫名字 爬取的域名（不用协议头） # 创建 crawl spider 模版 scrapy genspider -t crawl 爬虫名字 爬取的域名（不用协议头） 3、启动爬虫 scrapy crawl 爬虫名字 项目文件结构 项目名字 项目名字 spiders文件夹（存储的是爬虫文件"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Categories","item":"https://www.catguild.cn/category/"},{"@type":"ListItem","position":2,"name":"爬虫","item":"https://www.catguild.cn/category/practical/python/%E7%88%AC%E8%99%AB/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"爬虫","name":"爬虫","description":"爬虫框架 scrapy 1、创建新项目 scrapy startproject tutorial 2、创建爬虫文件 # 创建普通模版 scrapy genspider 爬虫名字 爬取的域名（不用协议头） # 创建 crawl spider 模版 scrapy genspider -t crawl 爬虫名字 爬取的域名（不用协议头） 3、启动爬虫 scrapy crawl 爬虫名字 项目文件结构 项目名字 项目名字 spiders文件夹（存储的是爬虫文件","keywords":[],"articleBody":"爬虫框架 scrapy 1、创建新项目\nscrapy startproject tutorial 2、创建爬虫文件\n# 创建普通模版 scrapy genspider 爬虫名字 爬取的域名（不用协议头） # 创建 crawl spider 模版 scrapy genspider -t crawl 爬虫名字 爬取的域名（不用协议头） 3、启动爬虫\nscrapy crawl 爬虫名字 项目文件结构 项目名字 项目名字 spiders文件夹（存储的是爬虫文件） init 自定义的爬虫文件\t核心功能文件 init items\t定义数据结构的地方\t爬取的数据包含那些 middleware\t中间件\t代理 settings\t配置文件\trobots协议\tua定义等 response的属性和方法 response.text\t获取的是响应的字符串 response.body\t获取的是二进制数据 response.xpath\t可以直接是xpath方法来解析response中的内容 response.extract()\t提取seletor对象的data属性值 response.extract_first()\t提取seletor列表的第一个数据 setting # 需要使用管道，需要打开该设置 ITEM_PIPELINES = { # 管道可以有多个，并有有优先级，值从1-1000，值越小越高 '项目名.pipelines.管道名': 300 } 下载图片 import urllib.request class DownLoadPipeline: def process_item(self, item, spider): url = item.get('url') filename='http://'+ item.get('name')+'.jpg' urllib.request.urlretrieve(url = url, filename = filename) return item 部署 scrapy部署服务器有一套完整的开源项目：scrapy+scrapyd(服务端)+scrapy-client(客户端)+scrapydweb 1、scrapyd(服务端)\n# 官方文档 https://scrapyd.readthedocs.io # 安装 pipenv install scrapyd # 启动 scrapyd # 浏览器访问 http://127.0.0.1:6800 2、scrapy-client scrapy-client它允许我们将本地的scrapy项目打包发送到scrapyd 这个服务端（前提是服务器scrapyd正常运行）\n# 官方文档 https://pypi.org/project/scrapyd-client/ # 安装 pipenv install scrapyd-client 3、scrapydweb（可选）\nScrapydWeb：用于Scrapyd集群管理的Web应用程序，支持Scrapy日志分析和可视化。\n#官方文档 https://github.com/my8100/scrapydweb/blob/master/README_CN.md # 安装 pipenv install scrapydweb # 运行命令 scrapydweb 运行命令scrapydweb，首次启动将会在当前目录下生成配置文件“scrapydweb_settings_v*.py”\n1、更改配置文件 编辑配置文件，将ENABLE_LOGPARSER更改为False\n2、添加访问权限\nSCRAPYD_SERVERS = [ '127.0.0.1:6800', # 'username:password@localhost:6801#group', ('username', 'password', 'localhost', '6801', 'group'), ] 3、添加http认证\nENABLE_AUTH = True USERNAME = 'username' PASSWORD = 'password' 如果启动失败（一般是使用了高版本的python） # 400 错误 APScheduler==3.9.1 # 500 错误 SQLAlchemy\u003e=1.2.15,\u003c1.4.0 ","wordCount":"845","inLanguage":"en","datePublished":"0001-01-01T00:00:00Z","dateModified":"0001-01-01T00:00:00Z","author":{"@type":"Person","name":"Me"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://www.catguild.cn/category/practical/python/%E7%88%AC%E8%99%AB/"},"publisher":{"@type":"Organization","name":"猫公会","logo":{"@type":"ImageObject","url":"https://www.catguild.cn/%3Clink%20/%20abs%20url%3E"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://www.catguild.cn/ accesskey=h title="Home (Alt + H)">Home</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://www.catguild.cn/archives/ title=⏱时间轴><span>⏱时间轴</span></a></li><li><a href=https://www.catguild.cn/categories/ title=分类><span>分类</span></a></li><li><a href=https://www.catguild.cn/tags/ title=🔖标签><span>🔖标签</span></a></li><li><a href=https://www.catguild.cn/search/ title="🔍搜索 (Alt + /)" accesskey=/><span>🔍搜索</span></a></li><li><a href=https://www.catguild.cn/links/ title=🤝友链><span>🤝友链</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://www.catguild.cn/>Home</a>&nbsp;»&nbsp;<a href=https://www.catguild.cn/category/>Categories</a></div><h1 class=post-title>爬虫</h1><div class=post-meta><style>i[id*=post_meta_style]{display:flex;align-items:center;margin:0 0 10px}.parent-post-meta{display:flex;flex-wrap:wrap;opacity:.8}</style><span class=parent-post-meta><span id=post_meta_style_1><span class="fa fa-calendar-check-o"></span>
<span>0001-01-01
&nbsp;&nbsp;</span></span>
<span id=post_meta_style_3><span class="fa fa-file-word-o"></span>
<span>845字
&nbsp;&nbsp;</span></span>
<span id=post_meta_style_4><span class="fa fa-clock-o"></span>
<span>2分钟
&nbsp;&nbsp;</span></span>
<span id=post_meta_style_6><span class="fa fa-tags" style=opacity:.8></span>
<span></span></span></span><span style=opacity:.8><span id=post_meta_style_7>&nbsp;&nbsp;
<span class="fa fa-eye"></span>
<span><span id=busuanzi_container_page_pv><span id=busuanzi_value_page_pv></span></span>
&nbsp;&nbsp;</span></span></div></header><aside id=toc-container class="toc-container wide"><div class=toc><details open><summary accesskey=c title="(Alt + C)"><span class=details>目录导航</span></summary><div class=inner><ul><li><a href=#%e7%88%ac%e8%99%ab%e6%a1%86%e6%9e%b6-scrapy aria-label="爬虫框架 scrapy">爬虫框架 scrapy</a><ul><li><a href=#%e9%a1%b9%e7%9b%ae%e6%96%87%e4%bb%b6%e7%bb%93%e6%9e%84 aria-label=项目文件结构>项目文件结构</a></li><li><a href=#response%e7%9a%84%e5%b1%9e%e6%80%a7%e5%92%8c%e6%96%b9%e6%b3%95 aria-label=response的属性和方法>response的属性和方法</a></li><li><a href=#setting aria-label=setting>setting</a></li><li><a href=#%e4%b8%8b%e8%bd%bd%e5%9b%be%e7%89%87 aria-label=下载图片>下载图片</a></li><li><a href=#%e9%83%a8%e7%bd%b2 aria-label=部署>部署</a></li><li><a href=#%e5%a6%82%e6%9e%9c%e5%90%af%e5%8a%a8%e5%a4%b1%e8%b4%a5%e4%b8%80%e8%88%ac%e6%98%af%e4%bd%bf%e7%94%a8%e4%ba%86%e9%ab%98%e7%89%88%e6%9c%ac%e7%9a%84python aria-label=如果启动失败（一般是使用了高版本的python）>如果启动失败（一般是使用了高版本的python）</a></li></ul></li></ul></div></details></div></aside><script>let activeElement,elements;window.addEventListener("DOMContentLoaded",function(){checkTocPosition(),elements=document.querySelectorAll("h1[id],h2[id],h3[id],h4[id],h5[id],h6[id]"),activeElement=elements[0];const t=encodeURI(activeElement.getAttribute("id")).toLowerCase();document.querySelector(`.inner ul li a[href="#${t}"]`).classList.add("active")},!1),window.addEventListener("resize",function(){checkTocPosition()},!1),window.addEventListener("scroll",()=>{activeElement=Array.from(elements).find(e=>{if(getOffsetTop(e)-window.pageYOffset>0&&getOffsetTop(e)-window.pageYOffset<window.innerHeight/2)return e})||activeElement,elements.forEach(e=>{const t=encodeURI(e.getAttribute("id")).toLowerCase();e===activeElement?document.querySelector(`.inner ul li a[href="#${t}"]`).classList.add("active"):document.querySelector(`.inner ul li a[href="#${t}"]`).classList.remove("active")})},!1);const main=parseInt(getComputedStyle(document.body).getPropertyValue("--article-width"),10),toc=parseInt(getComputedStyle(document.body).getPropertyValue("--toc-width"),10),gap=parseInt(getComputedStyle(document.body).getPropertyValue("--gap"),10);function checkTocPosition(){const e=document.body.scrollWidth;e-main-toc*2-gap*4>0?document.getElementById("toc-container").classList.add("wide"):document.getElementById("toc-container").classList.remove("wide")}function getOffsetTop(e){if(!e.getClientRects().length)return 0;let t=e.getBoundingClientRect(),n=e.ownerDocument.defaultView;return t.top+n.pageYOffset}</script><div class=post-content><h1 id=爬虫框架-scrapy>爬虫框架 scrapy<a hidden class=anchor aria-hidden=true href=#爬虫框架-scrapy>#</a></h1><p>1、创建新项目</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl>scrapy startproject tutorial
</span></span></code></pre></div><p>2、创建爬虫文件</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl><span class=c1># 创建普通模版</span>
</span></span><span class=line><span class=cl>scrapy genspider 爬虫名字 爬取的域名（不用协议头）
</span></span><span class=line><span class=cl><span class=c1># 创建 crawl spider 模版</span>
</span></span><span class=line><span class=cl>scrapy genspider -t crawl 爬虫名字 爬取的域名（不用协议头）
</span></span></code></pre></div><p>3、启动爬虫</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl>scrapy crawl 爬虫名字
</span></span></code></pre></div><h2 id=项目文件结构>项目文件结构<a hidden class=anchor aria-hidden=true href=#项目文件结构>#</a></h2><div class=highlight><pre tabindex=0 class=chroma><code class=language-txt data-lang=txt><span class=line><span class=cl>项目名字
</span></span><span class=line><span class=cl>	项目名字
</span></span><span class=line><span class=cl>		spiders文件夹（存储的是爬虫文件）
</span></span><span class=line><span class=cl>			init
</span></span><span class=line><span class=cl>			自定义的爬虫文件		核心功能文件
</span></span><span class=line><span class=cl>		init
</span></span><span class=line><span class=cl>		items		定义数据结构的地方		爬取的数据包含那些
</span></span><span class=line><span class=cl>		middleware		中间件		代理
</span></span><span class=line><span class=cl>		settings		配置文件		robots协议		ua定义等
</span></span></code></pre></div><h2 id=response的属性和方法>response的属性和方法<a hidden class=anchor aria-hidden=true href=#response的属性和方法>#</a></h2><div class=highlight><pre tabindex=0 class=chroma><code class=language-txt data-lang=txt><span class=line><span class=cl>response.text	获取的是响应的字符串
</span></span><span class=line><span class=cl>response.body	获取的是二进制数据
</span></span><span class=line><span class=cl>response.xpath	可以直接是xpath方法来解析response中的内容
</span></span><span class=line><span class=cl>response.extract()	提取seletor对象的data属性值
</span></span><span class=line><span class=cl>response.extract_first()	提取seletor列表的第一个数据
</span></span></code></pre></div><h2 id=setting>setting<a hidden class=anchor aria-hidden=true href=#setting>#</a></h2><div class=highlight><pre tabindex=0 class=chroma><code class=language-txt data-lang=txt><span class=line><span class=cl># 需要使用管道，需要打开该设置
</span></span><span class=line><span class=cl>ITEM_PIPELINES = {
</span></span><span class=line><span class=cl>	# 管道可以有多个，并有有优先级，值从1-1000，值越小越高
</span></span><span class=line><span class=cl>	&#39;项目名.pipelines.管道名&#39;: 300
</span></span><span class=line><span class=cl>}
</span></span></code></pre></div><h2 id=下载图片>下载图片<a hidden class=anchor aria-hidden=true href=#下载图片>#</a></h2><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>urllib.request</span>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>DownLoadPipeline</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>process_item</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>item</span><span class=p>,</span> <span class=n>spider</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>url</span> <span class=o>=</span> <span class=n>item</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s1>&#39;url&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>filename</span><span class=o>=</span><span class=s1>&#39;http://&#39;</span><span class=o>+</span> <span class=n>item</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s1>&#39;name&#39;</span><span class=p>)</span><span class=o>+</span><span class=s1>&#39;.jpg&#39;</span>
</span></span><span class=line><span class=cl>        <span class=n>urllib</span><span class=o>.</span><span class=n>request</span><span class=o>.</span><span class=n>urlretrieve</span><span class=p>(</span><span class=n>url</span> <span class=o>=</span> <span class=n>url</span><span class=p>,</span> <span class=n>filename</span> <span class=o>=</span> <span class=n>filename</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>item</span>
</span></span></code></pre></div><h2 id=部署>部署<a hidden class=anchor aria-hidden=true href=#部署>#</a></h2><p>scrapy部署服务器有一套完整的开源项目：<strong>scrapy+scrapyd(服务端)+scrapy-client(客户端)+scrapydweb</strong>
1、scrapyd(服务端)</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-txt data-lang=txt><span class=line><span class=cl># 官方文档
</span></span><span class=line><span class=cl>https://scrapyd.readthedocs.io
</span></span><span class=line><span class=cl># 安装
</span></span><span class=line><span class=cl>pipenv install scrapyd
</span></span><span class=line><span class=cl># 启动
</span></span><span class=line><span class=cl>scrapyd
</span></span><span class=line><span class=cl># 浏览器访问
</span></span><span class=line><span class=cl>http://127.0.0.1:6800
</span></span></code></pre></div><p>2、scrapy-client
scrapy-client它允许我们将本地的scrapy项目打包发送到scrapyd 这个服务端（前提是服务器scrapyd正常运行）</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-txt data-lang=txt><span class=line><span class=cl># 官方文档
</span></span><span class=line><span class=cl>https://pypi.org/project/scrapyd-client/
</span></span><span class=line><span class=cl># 安装
</span></span><span class=line><span class=cl>pipenv install scrapyd-client
</span></span></code></pre></div><p>3、scrapydweb（可选）</p><p>ScrapydWeb：用于Scrapyd集群管理的Web应用程序，支持Scrapy日志分析和可视化。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-txt data-lang=txt><span class=line><span class=cl>#官方文档
</span></span><span class=line><span class=cl>https://github.com/my8100/scrapydweb/blob/master/README_CN.md
</span></span><span class=line><span class=cl># 安装
</span></span><span class=line><span class=cl>pipenv install scrapydweb
</span></span><span class=line><span class=cl># 运行命令
</span></span><span class=line><span class=cl>scrapydweb
</span></span></code></pre></div><p>运行命令scrapydweb，首次启动将会在当前目录下生成配置文件“scrapydweb_settings_v*.py”</p><p>1、更改配置文件 编辑配置文件，将ENABLE_LOGPARSER更改为False</p><p>2、添加访问权限</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-txt data-lang=txt><span class=line><span class=cl>SCRAPYD_SERVERS = [
</span></span><span class=line><span class=cl>    &#39;127.0.0.1:6800&#39;,
</span></span><span class=line><span class=cl>    # &#39;username:password@localhost:6801#group&#39;,
</span></span><span class=line><span class=cl>    (&#39;username&#39;, &#39;password&#39;, &#39;localhost&#39;, &#39;6801&#39;, &#39;group&#39;),
</span></span><span class=line><span class=cl>]
</span></span></code></pre></div><p>3、添加http认证</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-txt data-lang=txt><span class=line><span class=cl>ENABLE_AUTH = True
</span></span><span class=line><span class=cl>USERNAME = &#39;username&#39;
</span></span><span class=line><span class=cl>PASSWORD = &#39;password&#39;
</span></span></code></pre></div><h2 id=如果启动失败一般是使用了高版本的python>如果启动失败（一般是使用了高版本的python）<a hidden class=anchor aria-hidden=true href=#如果启动失败一般是使用了高版本的python>#</a></h2><div class=highlight><pre tabindex=0 class=chroma><code class=language-txt data-lang=txt><span class=line><span class=cl># 400 错误
</span></span><span class=line><span class=cl>APScheduler==3.9.1
</span></span><span class=line><span class=cl># 500 错误
</span></span><span class=line><span class=cl>SQLAlchemy&gt;=1.2.15,&lt;1.4.0
</span></span></code></pre></div></div><footer class=post-footer><ul class=post-tags></ul><nav class=paginav><a class=prev href=https://www.catguild.cn/category/redis/redis%E9%9D%A2%E8%AF%95%E9%A2%98/><span class=title>« Prev</span><br><span>Redis面试题</span></a>
<a class=next href=https://www.catguild.cn/category/juc/%E7%BA%BF%E7%A8%8B%E4%B8%AD%E6%96%AD/><span class=title>Next »</span><br><span>线程中断</span></a></nav></footer></article></main><footer class=footer><span>Copyright
&copy;
2023-2023
<a href=https://www.catguild.cn/ style=color:#939393>猫公会</a>
All Rights Reserved</span><div class="footer-line thanks"><span class="icp footer-divider">特别感谢
<a href=https://gohugo.io target=_blank rel="external nofollow noopener noreferrer" title="Hugo 0.111.3">Hugo</a> |
<a href=https://github.com/adityatelange/hugo-PaperMod target=_blank rel=external title="PaperMod 7.0">PaperMod</a> |
<a href=https://github.com target=_blank rel="noopener noreffer">GitHub</a> |
<a href=https://vercel.com target=_blank rel="noopener noreffer">Vercel</a></span></div><div class="footer-line beian"><a href=https://beian.miit.gov.cn/ target=_blank style=color:#939393>皖ICP备 20012821 号</a>&nbsp;
<span><a target=_blank href="http://www.beian.gov.cn/portal/registerSystemInfo?recordcode=34082602201751" style=display:inline-block;text-decoration:none;height:20px;color:#939393><img src=/img/beian.png style="float:left;margin:0 5px 0 0">
皖公网安备 34082602201751 号</a></span></div></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><span class=topInner><svg class="topSvg" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg><span id=read_progress></span></span></a>
<script>document.addEventListener("scroll",function(){const t=document.getElementById("read_progress"),n=document.documentElement.scrollHeight,s=document.documentElement.clientHeight,o=document.documentElement.scrollTop||document.body.scrollTop;t.innerText=((o/(n-s)).toFixed(2)*100).toFixed(0)})</script><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>let mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>200||document.documentElement.scrollTop>200?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{(function(){document.cookie="change-themes="+escape("false")})(),document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>